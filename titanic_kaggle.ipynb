{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Titanic: Machine Learning from Disaster\n",
    "Olivier RISSER-MAROIX (VieVie31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphlab as gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-03-18 15:15:53,119 [INFO] graphlab.cython.cy_server, 176: GraphLab Create v1.8.4 started. Logging: /tmp/graphlab_server_1458310552.log\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/mac/Desktop/titanic/train.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/mac/Desktop/titanic/train.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.029997 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.029997 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create is assigned to orissermaroix@gmail.com and will expire on March 12, 2017. For commercial licensing options, visit https://dato.com/buy/.\n",
      "------------------------------------------------------"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/mac/Desktop/titanic/train.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/mac/Desktop/titanic/train.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 891 lines in 0.012151 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 891 lines in 0.012151 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/mac/Desktop/titanic/test.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/mac/Desktop/titanic/test.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.010295 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.010295 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[int,int,int,str,str,float,int,int,str,float,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n",
      "------------------------------------------------------"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/mac/Desktop/titanic/test.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/mac/Desktop/titanic/test.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 418 lines in 0.008131 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 418 lines in 0.008131 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[int,int,str,str,float,int,int,str,float,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "data_train = gl.load_sframe(\"train.csv\")\n",
    "data_test = gl.load_sframe(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">PassengerId</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Survived</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Pclass</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Name</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Sex</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Age</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">SibSp</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Parch</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Ticket</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Braund, Mr. Owen Harris</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">male</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">22.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">A/5 21171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Cumings, Mrs. John<br>Bradley (Florence Briggs ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">female</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">38.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">PC 17599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Heikkinen, Miss. Laina</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">female</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">26.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">STON/O2. 3101282</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Fare</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Cabin</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7.25</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\"></td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">71.2833</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">C85</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7.925</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\"></td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">S</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[3 rows x 12 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tPassengerId\tint\n",
       "\tSurvived\tint\n",
       "\tPclass\tint\n",
       "\tName\tstr\n",
       "\tSex\tstr\n",
       "\tAge\tfloat\n",
       "\tSibSp\tint\n",
       "\tParch\tint\n",
       "\tTicket\tstr\n",
       "\tFare\tfloat\n",
       "\tCabin\tstr\n",
       "\tEmbarked\tstr\n",
       "\n",
       "Rows: 3\n",
       "\n",
       "Data:\n",
       "+-------------+----------+--------+-------------------------------+--------+\n",
       "| PassengerId | Survived | Pclass |              Name             |  Sex   |\n",
       "+-------------+----------+--------+-------------------------------+--------+\n",
       "|      1      |    0     |   3    |    Braund, Mr. Owen Harris    |  male  |\n",
       "|      2      |    1     |   1    | Cumings, Mrs. John Bradley... | female |\n",
       "|      3      |    1     |   3    |     Heikkinen, Miss. Laina    | female |\n",
       "+-------------+----------+--------+-------------------------------+--------+\n",
       "+------+-------+-------+------------------+---------+-------+----------+\n",
       "| Age  | SibSp | Parch |      Ticket      |   Fare  | Cabin | Embarked |\n",
       "+------+-------+-------+------------------+---------+-------+----------+\n",
       "| 22.0 |   1   |   0   |    A/5 21171     |   7.25  |       |    S     |\n",
       "| 38.0 |   1   |   0   |     PC 17599     | 71.2833 |  C85  |    C     |\n",
       "| 26.0 |   0   |   0   | STON/O2. 3101282 |  7.925  |       |    S     |\n",
       "+------+-------+-------+------------------+---------+-------+----------+\n",
       "[3 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Cleanning trainning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train[\"male\"] = data_train[\"Sex\"] == \"male\"\n",
    "data_train[\"female\"] = data_train[\"Sex\"] == \"female\"\n",
    "data_train = data_train.remove_column(\"Sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train[\"no_age\"] = data_train[\"Age\"] == None\n",
    "data_train[\"Age\"] = gl.SArray([0 if v == None else v for v in data_train[\"Age\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train[\"embarked_s\"] = data_train[\"Embarked\"] == \"S\"\n",
    "data_train[\"embarked_c\"] = data_train[\"Embarked\"] == \"C\"\n",
    "data_train[\"embarked_q\"] = data_train[\"Embarked\"] == \"Q\"\n",
    "data_train[\"embarked_none\"] = data_train[\"Embarked\"] == None\n",
    "data_train = data_train.remove_column(\"Embarked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train[\"1_class\"] = data_train[\"Pclass\"] == 1\n",
    "data_train[\"2_class\"] = data_train[\"Pclass\"] == 2\n",
    "data_train[\"3_class\"] = data_train[\"Pclass\"] == 3\n",
    "data_train = data_train.remove_column(\"Pclass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function create in module graphlab.toolkits.classifier.logistic_classifier:\n",
      "\n",
      "create(dataset, target, features=None, l2_penalty=0.01, l1_penalty=0.0, solver='auto', feature_rescaling=True, convergence_threshold=0.01, step_size=1.0, lbfgs_memory_level=11, max_iterations=10, class_weights=None, validation_set='auto', verbose=True)\n",
      "    Create a :class:`~graphlab.logistic_classifier.LogisticClassifier` (using\n",
      "    logistic regression as a classifier) to predict the class of a discrete\n",
      "    target variable (binary or multiclass) based on a model of class probability\n",
      "    as a logistic function of a linear combination of the features.  In addition\n",
      "    to standard numeric and categorical types, features can also be extracted\n",
      "    automatically from list or dictionary-type SFrame columns.\n",
      "    \n",
      "    This model can be regularized with an l1 penalty, an l2 penalty, or both. By\n",
      "    default this model has an l2 regularization weight of 0.01.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    dataset : SFrame\n",
      "        Dataset for training the model.\n",
      "    \n",
      "    target : string\n",
      "        Name of the column containing the target variable. The values in this\n",
      "        column must be of string or integer type. String target variables are\n",
      "        automatically mapped to integers in the order in which they are provided.\n",
      "        For example, a target variable with 'cat' and 'dog' as possible\n",
      "        values is mapped to 0 and 1 respectively with 0 being the base class\n",
      "        and 1 being the reference class. Use `model['classes']` to retrieve\n",
      "        the order in which the classes are mapped.\n",
      "    \n",
      "    features : list[string], optional\n",
      "        Names of the columns containing features. 'None' (the default) indicates\n",
      "        that all columns except the target variable should be used as features.\n",
      "    \n",
      "        The features are columns in the input SFrame that can be of the\n",
      "        following types:\n",
      "    \n",
      "        - *Numeric*: values of numeric type integer or float.\n",
      "    \n",
      "        - *Categorical*: values of type string.\n",
      "    \n",
      "        - *Array*: list of numeric (integer or float) values. Each list element\n",
      "          is treated as a separate feature in the model.\n",
      "    \n",
      "        - *Dictionary*: key-value pairs with numeric (integer or float) values\n",
      "          Each key of a dictionary is treated as a separate feature and the\n",
      "          value in the dictionary corresponds to the value of the feature.\n",
      "          Dictionaries are ideal for representing sparse data.\n",
      "    \n",
      "        Columns of type *list* are not supported. Convert such feature\n",
      "        columns to type array if all entries in the list are of numeric\n",
      "        types. If the lists contain data of mixed types, separate\n",
      "        them out into different columns.\n",
      "    \n",
      "    l2_penalty : float, optional\n",
      "        Weight on l2 regularization of the model. The larger this weight, the\n",
      "        more the model coefficients shrink toward 0. This introduces bias into\n",
      "        the model but decreases variance, potentially leading to better\n",
      "        predictions. The default value is 0.01; setting this parameter to 0\n",
      "        corresponds to unregularized logistic regression. See the ridge\n",
      "        regression reference for more detail.\n",
      "    \n",
      "    l1_penalty : float, optional\n",
      "        Weight on l1 regularization of the model. Like the l2 penalty, the\n",
      "        higher the l1 penalty, the more the estimated coefficients shrink toward\n",
      "        0. The l1 penalty, however, completely zeros out sufficiently small\n",
      "        coefficients, automatically indicating features that are not useful\n",
      "        for the model. The default weight of 0 prevents any features from\n",
      "        being discarded. See the LASSO regression reference for more detail.\n",
      "    \n",
      "    solver : string, optional\n",
      "        Name of the solver to be used to solve the regression. See the\n",
      "        references for more detail on each solver. Available solvers are:\n",
      "    \n",
      "        - *auto (default)*: automatically chooses the best solver for the data\n",
      "          and model parameters.\n",
      "        - *newton*: Newton-Raphson\n",
      "        - *lbfgs*: limited memory BFGS\n",
      "        - *fista*: accelerated gradient descent\n",
      "    \n",
      "        For this model, the Newton-Raphson method is equivalent to the\n",
      "        iteratively re-weighted least squares algorithm. If the l1_penalty is\n",
      "        greater than 0, use the 'fista' solver.\n",
      "    \n",
      "        The model is trained using a carefully engineered collection of methods\n",
      "        that are automatically picked based on the input data. The ``newton``\n",
      "        method  works best for datasets with plenty of examples and few features\n",
      "        (long datasets). Limited memory BFGS (``lbfgs``) is a robust solver for\n",
      "        wide datasets (i.e datasets with many coefficients).  ``fista`` is the\n",
      "        default solver for l1-regularized linear regression. The solvers are all\n",
      "        automatically tuned and the default options should function well. See\n",
      "        the solver options guide for setting additional parameters for each of\n",
      "        the solvers.\n",
      "    \n",
      "        See the user guide for additional details on how the solver is chosen.\n",
      "        (see `here\n",
      "        <https://dato.com/learn/userguide/supervised-learning/linear-regression.html>`_)\n",
      "    \n",
      "    \n",
      "    \n",
      "    feature_rescaling : boolean, optional\n",
      "    \n",
      "        Feature rescaling is an important pre-processing step that ensures that\n",
      "        all features are on the same scale. An l2-norm rescaling is performed\n",
      "        to make sure that all features are of the same norm. Categorical\n",
      "        features are also rescaled by rescaling the dummy variables that are\n",
      "        used to represent them. The coefficients are returned in original scale\n",
      "        of the problem. This process is particularly useful when features\n",
      "        vary widely in their ranges.\n",
      "    \n",
      "    \n",
      "    convergence_threshold : float, optional\n",
      "    \n",
      "        Convergence is tested using variation in the training objective. The\n",
      "        variation in the training objective is calculated using the difference\n",
      "        between the objective values between two steps. Consider reducing this\n",
      "        below the default value (0.01) for a more accurately trained model.\n",
      "        Beware of overfitting (i.e a model that works well only on the training\n",
      "        data) if this parameter is set to a very low value.\n",
      "    \n",
      "    lbfgs_memory_level : float, optional\n",
      "    \n",
      "        The L-BFGS algorithm keeps track of gradient information from the\n",
      "        previous ``lbfgs_memory_level`` iterations. The storage requirement for\n",
      "        each of these gradients is the ``num_coefficients`` in the problem.\n",
      "        Increasing the ``lbfgs_memory_level ``can help improve the quality of\n",
      "        the model trained. Setting this to more than ``max_iterations`` has the\n",
      "        same effect as setting it to ``max_iterations``.\n",
      "    \n",
      "    max_iterations : float, optional\n",
      "    \n",
      "        The maximum number of allowed passes through the data. More passes over\n",
      "        the data can result in a more accurately trained model. Consider\n",
      "        increasing this (the default value is 10) if the training accuracy is\n",
      "        low and the *Grad-Norm* in the display is large.\n",
      "    \n",
      "    step_size : float, optional\n",
      "    \n",
      "        The starting step size to use for the ``fista`` solver. The default is\n",
      "        set to 1.0, this is an aggressive setting. If the first iteration takes\n",
      "        a considerable amount of time, reducing this parameter may speed up\n",
      "        model training.\n",
      "    \n",
      "    class_weights : {dict, `auto`}, optional\n",
      "    \n",
      "        Weights the examples in the training data according to the given class\n",
      "        weights. If set to `None`, all classes are supposed to have weight one. The\n",
      "        `auto` mode set the class weight to be inversely proportional to number of\n",
      "        examples in the training data with the given class.\n",
      "    \n",
      "    validation_set : SFrame, optional\n",
      "    \n",
      "        A dataset for monitoring the model's generalization performance.\n",
      "        For each row of the progress table, the chosen metrics are computed\n",
      "        for both the provided training dataset and the validation_set. The\n",
      "        format of this SFrame must be the same as the training set.\n",
      "        By default this argument is set to 'auto' and a validation set is\n",
      "        automatically sampled and used for progress printing. If\n",
      "        validation_set is set to None, then no additional metrics\n",
      "        are computed. The default value is 'auto'.\n",
      "    \n",
      "    \n",
      "    verbose : bool, optional\n",
      "        If True, print progress updates.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    out : LogisticClassifier\n",
      "        A trained model of type\n",
      "        :class:`~graphlab.logistic_classifier.LogisticClassifier`.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    LogisticClassifier, graphlab.boosted_trees_classifier.BoostedTreesClassifier,\n",
      "    graphlab.svm_classifier.SVMClassifier, graphlab.classifier.create\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    - Categorical variables are encoded by creating dummy variables. For a\n",
      "      variable with :math:`K` categories, the encoding creates :math:`K-1` dummy\n",
      "      variables, while the first category encountered in the data is used as the\n",
      "      baseline.\n",
      "    \n",
      "    - For prediction and evaluation of logistic regression models with sparse\n",
      "      dictionary inputs, new keys/columns that were not seen during training\n",
      "      are silently ignored.\n",
      "    \n",
      "    - During model creation, 'None' values in the data will result in an error\n",
      "      being thrown.\n",
      "    \n",
      "    - A constant term is automatically added for the model intercept. This term\n",
      "      is not regularized.\n",
      "    \n",
      "    - Standard errors on coefficients are only availiable when `solver=newton`\n",
      "      or when the default `auto` solver option choses the newton method and if\n",
      "      the number of examples in the training data is more than the number of\n",
      "      coefficients. If standard errors cannot be estimated, a column of `None`\n",
      "      values are returned.\n",
      "    \n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    - `Wikipedia - logistic regression\n",
      "      <http://en.wikipedia.org/wiki/Logistic_regression>`_\n",
      "    \n",
      "    - Hoerl, A.E. and Kennard, R.W. (1970) `Ridge regression: Biased Estimation\n",
      "      for Nonorthogonal Problems\n",
      "      <http://amstat.tandfonline.com/doi/abs/10.1080/00401706.1970.10488634>`_.\n",
      "      Technometrics 12(1) pp.55-67\n",
      "    \n",
      "    - Tibshirani, R. (1996) `Regression Shrinkage and Selection via the Lasso <h\n",
      "      ttp://www.jstor.org/discover/10.2307/2346178?uid=3739256&uid=2&uid=4&sid=2\n",
      "      1104169934983>`_. Journal of the Royal Statistical Society. Series B\n",
      "      (Methodological) 58(1) pp.267-288.\n",
      "    \n",
      "    - Zhu, C., et al. (1997) `Algorithm 778: L-BFGS-B: Fortran subroutines for\n",
      "      large-scale bound-constrained optimization\n",
      "      <http://dl.acm.org/citation.cfm?id=279236>`_. ACM Transactions on\n",
      "      Mathematical Software 23(4) pp.550-560.\n",
      "    \n",
      "    - Beck, A. and Teboulle, M. (2009) `A Fast Iterative Shrinkage-Thresholding\n",
      "      Algorithm for Linear Inverse Problems\n",
      "      <http://epubs.siam.org/doi/abs/10.1137/080716542>`_. SIAM Journal on\n",
      "      Imaging Sciences 2(1) pp.183-202.\n",
      "    \n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    \n",
      "    Given an :class:`~graphlab.SFrame` ``sf``, a list of feature columns\n",
      "    [``feature_1`` ... ``feature_K``], and a target column ``target`` with 0 and\n",
      "    1 values, create a\n",
      "    :class:`~graphlab.logistic_classifier.LogisticClassifier` as follows:\n",
      "    \n",
      "    >>> data =  graphlab.SFrame('http://s3.amazonaws.com/dato-datasets/regression/houses.csv')\n",
      "    >>> data['is_expensive'] = data['price'] > 30000\n",
      "    >>> model = graphlab.logistic_classifier.create(data, 'is_expensive')\n",
      "    \n",
      "    By default all columns of ``data`` except the target are used as features, but\n",
      "    specific feature columns can be specified manually.\n",
      "    \n",
      "    >>> model = graphlab.logistic_classifier.create(data, 'is_expensive', ['bedroom', 'size'])\n",
      "    \n",
      "    \n",
      "    .. sourcecode:: python\n",
      "    \n",
      "      # L2 regularizer\n",
      "      >>> model_ridge = graphlab.logistic_classifier.create(data, 'is_expensive', l2_penalty=0.1)\n",
      "    \n",
      "      # L1 regularizer\n",
      "      >>> model_lasso = graphlab.logistic_classifier.create(data, 'is_expensive', l2_penalty=0.,\n",
      "                                                                   l1_penalty=1.0)\n",
      "    \n",
      "      # Both L1 and L2 regularizer\n",
      "      >>> model_enet  = graphlab.logistic_classifier.create(data, 'is_expensive', l2_penalty=0.5, l1_penalty=0.5)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(gl.classifier.logistic_classifier.create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set_1, train_set_2 = data_train.random_split(.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-------------------------------+------+-------+-------+\n",
      "| PassengerId | Survived |              Name             | Age  | SibSp | Parch |\n",
      "+-------------+----------+-------------------------------+------+-------+-------+\n",
      "|      2      |    1     | Cumings, Mrs. John Bradley... | 38.0 |   1   |   0   |\n",
      "+-------------+----------+-------------------------------+------+-------+-------+\n",
      "+----------+---------+-------+------+--------+--------+------------+------------+\n",
      "|  Ticket  |   Fare  | Cabin | male | female | no_age | embarked_s | embarked_c |\n",
      "+----------+---------+-------+------+--------+--------+------------+------------+\n",
      "| PC 17599 | 71.2833 |  C85  |  0   |   1    |   0    |     0      |     1      |\n",
      "+----------+---------+-------+------+--------+--------+------------+------------+\n",
      "+------------+---------------+---------+---------+---------+\n",
      "| embarked_q | embarked_none | 1_class | 2_class | 3_class |\n",
      "+------------+---------------+---------+---------+---------+\n",
      "|     0      |       0       |    1    |    0    |    0    |\n",
      "+------------+---------------+---------+---------+---------+\n",
      "[1 rows x 19 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print train_set_1.head(1)\n",
    "features = [\"Age\", \"SibSp\", \"Parch\", \"Fare\", \"male\", \"female\", \"no_age\", \n",
    "            \"embarked_s\", \"embarked_c\", \"embarked_q\", \"embarked_none\",\n",
    "            \"1_class\", \"2_class\", \"3_class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>WARNING: Detected extremely low variance for feature(s) 'embarked_none' because all entries are nearly the same.\n",
       "Proceeding with model training using all features. If the model does not provide results of adequate quality, exclude the above mentioned feature(s) from the input dataset.</pre>"
      ],
      "text/plain": [
       "WARNING: Detected extremely low variance for feature(s) 'embarked_none' because all entries are nearly the same.\n",
       "Proceeding with model training using all features. If the model does not provide results of adequate quality, exclude the above mentioned feature(s) from the input dataset."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 718</pre>"
      ],
      "text/plain": [
       "Number of examples          : 718"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 14</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 14</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 15</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting Newton Method</pre>"
      ],
      "text/plain": [
       "Starting Newton Method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Elapsed Time | Training-accuracy | Validation-accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Elapsed Time | Training-accuracy | Validation-accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 2        | 1.085226     | 0.799443          | 0.809249            |</pre>"
      ],
      "text/plain": [
       "| 1         | 2        | 1.085226     | 0.799443          | 0.809249            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 3        | 1.097328     | 0.798050          | 0.820809            |</pre>"
      ],
      "text/plain": [
       "| 2         | 3        | 1.097328     | 0.798050          | 0.820809            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 4        | 1.100741     | 0.795265          | 0.820809            |</pre>"
      ],
      "text/plain": [
       "| 3         | 4        | 1.100741     | 0.795265          | 0.820809            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 5        | 1.103611     | 0.795265          | 0.820809            |</pre>"
      ],
      "text/plain": [
       "| 4         | 5        | 1.103611     | 0.795265          | 0.820809            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>SUCCESS: Optimal solution found.</pre>"
      ],
      "text/plain": [
       "SUCCESS: Optimal solution found."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre></pre>"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simple_logistic_classifier = gl.classifier.logistic_classifier.create(train_set_1, target=\"Survived\", \n",
    "                                                                      features=features, validation_set=train_set_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Cleanning testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test[\"male\"] = data_test[\"Sex\"] == \"male\"\n",
    "data_test[\"female\"] = data_test[\"Sex\"] == \"female\"\n",
    "data_test = data_test.remove_column(\"Sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test[\"no_age\"] = data_test[\"Age\"] == None\n",
    "data_test[\"Age\"] = gl.SArray([0 if v == None else v for v in data_test[\"Age\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test[\"embarked_s\"] = data_test[\"Embarked\"] == \"S\"\n",
    "data_test[\"embarked_c\"] = data_test[\"Embarked\"] == \"C\"\n",
    "data_test[\"embarked_q\"] = data_test[\"Embarked\"] == \"Q\"\n",
    "data_test[\"embarked_none\"] = data_test[\"Embarked\"] == None\n",
    "data_test = data_test.remove_column(\"Embarked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test[\"1_class\"] = data_test[\"Pclass\"] == 1\n",
    "data_test[\"2_class\"] = data_test[\"Pclass\"] == 2\n",
    "data_test[\"3_class\"] = data_test[\"Pclass\"] == 3\n",
    "data_test = data_test.remove_column(\"Pclass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_test[\"Survived\"] = simple_logistic_classifier.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = gl.SFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission[\"PassengerId\"] = data_test[\"PassengerId\"]\n",
    "submission[\"Survived\"] = data_test[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.save(\"kaggle.csv\", format=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
